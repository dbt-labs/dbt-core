# dbt run

## Overview

`dbt run` compiles and executes models against the target database. It's the core command for materializing SQL and Python models as tables, views, or incremental updates.

**Reference**: https://docs.getdbt.com/reference/commands/run

## Task Class: `RunTask`

`RunTask` extends `CompileTask` (which extends `GraphRunnableTask`) and is the base class for most execution commands. Key characteristics:

- **Runner**: Uses `ModelRunner` for standard models, `MicrobatchModelRunner` for microbatch incremental models
- **Resource Types**: Models only (`NodeType.Model`)
- **Error Handling**: `raise_on_first_error()` returns `False`—continues processing other nodes after failures
- **Hooks**: Executes `on-run-start` and `on-run-end` hooks via `safe_run_hooks()`

### Execution Flow

1. **before_run()**: Creates schemas, populates adapter cache, calls `defer_to_manifest()` if `--defer` is set
2. **Hook execution**: Runs `on-run-start` hooks
3. **Node execution**: For each selected model, `ModelRunner` compiles and materializes
4. **Hook execution**: Runs `on-run-end` hooks

### ModelRunner

`ModelRunner` extends `CompileRunner` and handles the compile-then-execute lifecycle:

```
compile() → execute() → after_execute()
```

In `execute()`:
1. Generates runtime context via `generate_runtime_model_context()`
2. Looks up materialization macro via `manifest.find_materialization_macro_by_name()`
3. Invokes the macro via `MacroGenerator`
4. Caches created relations for the adapter cache
5. Returns `RunResult`

## Implementation Quirks

### Tracking

`RunTask` includes model run tracking via `track_model_run()` which sends anonymized telemetry including execution time, materialization type, incremental strategy, contract enforcement status, and versioning.

### Empty Execution

The `--empty` flag allows running with `LIMIT 0` to test compilation and downstream effects without processing data. This is handled by models' ref/source resolution injecting empty result sets.

## Microbatch Models

Microbatch is a special incremental strategy for processing time-series data in batches. When a model has `incremental_strategy='microbatch'`, dbt uses `MicrobatchModelRunner` instead of `ModelRunner`.

### How Microbatch Works

Rather than processing all data in a single transaction, microbatch:

1. Divides the time range into batches based on `batch_size` (hour, day, month, year)
2. Executes each batch as a separate transaction
3. Supports parallel batch execution after the first batch succeeds
4. Tracks batch-level success/failure for retry capability

### Key Classes

**`MicrobatchBuilder`** (`core/dbt/materializations/incremental/microbatch.py`):
- Constructs batch definitions from model config (`begin`, `batch_size`, `lookback`)
- Builds start/end times for each batch
- Creates Jinja context for batch execution

**`MicrobatchModelRunner`**:
- Orchestrates batch execution
- Manages parallel execution via thread pool
- Tracks `relation_exists` to know when parallel execution is safe

**`BatchRunner`**:
- Handles single batch execution
- Called by `MicrobatchModelRunner._execute_microbatch_materialization()`

### Batch Execution Flow

```
MicrobatchModelRunner.execute()
  └── For each batch:
        └── BatchRunner._execute_microbatch_materialization()
              ├── Build jinja context with batch bounds
              ├── Execute materialization macro
              └── Return batch result
```

### CLI Flags for Microbatch

| Flag | Description |
|------|-------------|
| `--event-time-start` | Override start time for batch range |
| `--event-time-end` | Override end time for batch range |

### Retry Behavior

Microbatch models support granular retry—only failed batches are re-executed on `dbt retry`. This is tracked via `batch_results` in `RunResult`, which stores `BatchResults` containing `successful` and `failed` batch lists.

When retrying:
- If some batches succeeded previously, only failed batches run
- If no batches succeeded, the model runs in full-refresh mode (to handle schema changes)

### Configuration

```yaml
models:
  my_model:
    materialized: incremental
    incremental_strategy: microbatch
    batch_size: day  # hour, day, month, year
    begin: '2020-01-01'
    lookback: 1  # number of batches to re-process for late-arriving data
```
